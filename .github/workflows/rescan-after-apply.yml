name: Security Pipeline - 04 Verify FAIL Reduction

on:
  workflow_dispatch:
    inputs:
      triggered_by:
        description: "Trigger reason (e.g. manual, no-remediation-needed)"
        required: false
        default: "manual"
  workflow_run:
    workflows: ["Security Pipeline - 03 Apply Merged Generated Terraform Remediation"]
    types: [completed]

concurrency:
  group: security-pipeline-04-rescan-${{ github.ref }}
  cancel-in-progress: true

permissions:
  id-token: write
  contents: read
  pull-requests: write
  actions: read

jobs:
  rescan:
    if: ${{ github.event_name == 'workflow_dispatch' || github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: ap-northeast-2

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "prowler>=3.11,<4.0"

      - name: Wait for eventual consistency
        run: sleep 150

      - name: Run post-apply Prowler (Seoul + CIS/ISMS-P)
        run: |
          mkdir -p artifacts/rescan
          prowler aws --region ap-northeast-2 --compliance cis_1.4_aws -M json-asff -o artifacts/rescan -F post_cis || true
          CHECKS="$(tr '\n' ' ' < iac/compliance/isms_p_checks.txt | xargs)"
          if [ -n "$CHECKS" ]; then
            prowler aws --region ap-northeast-2 -c $CHECKS -M json-asff -o artifacts/rescan -F post_isms_p || true
          fi
          python iac/scripts/merge_prowler_outputs.py \
            --dir artifacts/rescan \
            --prefix post \
            --output artifacts/rescan/post.asff.json
          python iac/scripts/normalize_findings.py \
            --input artifacts/rescan/post.asff.json \
            --output artifacts/rescan/post_normalized.json \
            --region ap-northeast-2

      - name: Download latest successful baseline scan artifact
        shell: bash
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          mkdir -p artifacts/baseline_scan
          RID="$(gh run list --workflow "Security Pipeline - 01 Scan Baseline" --repo "${{ github.repository }}" --limit 30 --json databaseId,conclusion --jq '[.[] | select(.conclusion=="success")][0].databaseId')"
          if [ -n "$RID" ] && [ "$RID" != "null" ]; then
            gh run download "$RID" --repo "${{ github.repository }}" --name "scan-$RID" --dir artifacts/baseline_scan || true
          fi

      - name: Download previous successful rescan artifact (for incremental delta)
        shell: bash
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          mkdir -p artifacts/previous_rescan
          PREV_RID="$(gh run list --workflow "Security Pipeline - 04 Verify FAIL Reduction" --repo "${{ github.repository }}" --limit 30 --json databaseId,conclusion --jq '[.[] | select(.conclusion=="success" and (.databaseId|tostring)!="${{ github.run_id }}")][0].databaseId')"
          if [ -n "$PREV_RID" ] && [ "$PREV_RID" != "null" ]; then
            echo "previous_rescan_run_id=$PREV_RID" >> "$GITHUB_ENV"
            gh run download "$PREV_RID" --repo "${{ github.repository }}" --name "rescan-$PREV_RID" --dir artifacts/previous_rescan || true
          fi

      - name: Compare baseline vs post
        run: |
          BASELINE_DOC="remediation/manifest.json"
          if [ -f "artifacts/baseline_scan/scan_manifest.json" ]; then
            BASELINE_DOC="artifacts/baseline_scan/scan_manifest.json"
          fi
          python iac/scripts/compare_failures.py \
            --baseline "$BASELINE_DOC" \
            --post artifacts/rescan/post_normalized.json \
            --output artifacts/rescan/rescan_summary.json
          python - <<'PY'
          import json
          from pathlib import Path
          summary_path = Path('artifacts/rescan/rescan_summary.json')
          s = json.loads(summary_path.read_text(encoding='utf-8'))
          current_post = json.loads(Path('artifacts/rescan/post_normalized.json').read_text(encoding='utf-8'))
          current_fail_rows = [x for x in current_post if x.get('status') == 'FAIL']
          current_fail_ids = sorted({x.get('check_id', 'unknown') for x in current_fail_rows})
          manual_override_ids = set()
          merged_manifest = Path('remediation/manifest.json')
          if merged_manifest.exists():
            try:
              merged_doc = json.loads(merged_manifest.read_text(encoding='utf-8'))
              for cat in merged_doc.get('categories', []) or []:
                for cid in cat.get('manual_required', []) or []:
                  cid_s = str(cid).strip()
                  if cid_s:
                    manual_override_ids.add(cid_s)

              check_map = merged_doc.get('check_map', {}) or {}
              for cid, entry in check_map.items():
                entries = entry if isinstance(entry, list) else [entry]
                for e in entries:
                  tier = str((e or {}).get('remediation_tier', '')).strip().lower()
                  if tier == 'manual-runbook':
                    cid_s = str(cid).strip()
                    if cid_s:
                      manual_override_ids.add(cid_s)
            except Exception:
              pass
          for cat_manifest in Path("remediation").glob("*/manifest.json"):
            try:
              cat_doc = json.loads(cat_manifest.read_text(encoding='utf-8'))
              for item in cat_doc.get("items", []) or []:
                cid = str(item.get("check_id", "")).strip()
                if cid and bool(item.get("manual_required")):
                  manual_override_ids.add(cid)
            except Exception:
              pass

          def is_manual_runbook(row):
            tier = str(row.get('remediation_tier', '')).strip().lower()
            cid = str(row.get('check_id', '')).strip()
            return (
              bool(row.get('manual_required'))
              or bool(row.get('non_terraform'))
              or tier == 'manual-runbook'
              or cid in manual_override_ids
            )

          total_fail_counts = {}
          remediable_fail_counts = {}
          manual_fail_counts = {}
          for row in current_fail_rows:
            cid = str(row.get('check_id', 'unknown'))
            total_fail_counts[cid] = total_fail_counts.get(cid, 0) + 1
            if is_manual_runbook(row):
              manual_fail_counts[cid] = manual_fail_counts.get(cid, 0) + 1
            else:
              remediable_fail_counts[cid] = remediable_fail_counts.get(cid, 0) + 1

          current_remediable_fail = len([r for r in current_fail_rows if not is_manual_runbook(r)])
          current_manual_fail = len([r for r in current_fail_rows if is_manual_runbook(r)])
          s['post_fail_remediable'] = current_remediable_fail
          s['post_fail_manual_runbook'] = current_manual_fail

          prev_summary_path = Path('artifacts/previous_rescan/rescan_summary.json')
          prev_post_path = Path('artifacts/previous_rescan/post_normalized.json')
          previous_post_fail = None
          incremental_reduced = None
          previous_post_remediable_fail = None
          incremental_reduced_remediable = None
          resolved_since_previous = []
          new_fail_since_previous = []
          resolved_since_previous_remediable = []
          new_fail_since_previous_remediable = []

          if prev_summary_path.exists():
            prev_summary = json.loads(prev_summary_path.read_text(encoding='utf-8'))
            previous_post_fail = int(prev_summary.get('post_fail', 0))
            incremental_reduced = previous_post_fail - int(s.get('post_fail', 0))
            s['previous_post_fail'] = previous_post_fail
            s['incremental_reduced'] = incremental_reduced
            if 'post_fail_remediable' in prev_summary:
              previous_post_remediable_fail = int(prev_summary.get('post_fail_remediable', 0))
              incremental_reduced_remediable = previous_post_remediable_fail - int(current_remediable_fail)
              s['previous_post_fail_remediable'] = previous_post_remediable_fail
              s['incremental_reduced_remediable'] = incremental_reduced_remediable

          if prev_post_path.exists():
            prev_post = json.loads(prev_post_path.read_text(encoding='utf-8'))
            prev_fail_rows = [x for x in prev_post if x.get('status') == 'FAIL']
            prev_fail_ids = sorted({x.get('check_id', 'unknown') for x in prev_fail_rows})
            prev_remediable_ids = sorted({x.get('check_id', 'unknown') for x in prev_fail_rows if not is_manual_runbook(x)})
            current_remediable_ids = sorted({x.get('check_id', 'unknown') for x in current_fail_rows if not is_manual_runbook(x)})
            resolved_since_previous = sorted(set(prev_fail_ids) - set(current_fail_ids))
            new_fail_since_previous = sorted(set(current_fail_ids) - set(prev_fail_ids))
            s['resolved_since_previous_check_ids'] = resolved_since_previous
            s['new_fail_since_previous_check_ids'] = new_fail_since_previous
            resolved_since_previous_remediable = sorted(set(prev_remediable_ids) - set(current_remediable_ids))
            new_fail_since_previous_remediable = sorted(set(current_remediable_ids) - set(prev_remediable_ids))
            s['resolved_since_previous_remediable_check_ids'] = resolved_since_previous_remediable
            s['new_fail_since_previous_remediable_check_ids'] = new_fail_since_previous_remediable
            if previous_post_remediable_fail is None:
              previous_post_remediable_fail = len(prev_remediable_ids)
              incremental_reduced_remediable = previous_post_remediable_fail - int(current_remediable_fail)
              s['previous_post_fail_remediable'] = previous_post_remediable_fail
              s['incremental_reduced_remediable'] = incremental_reduced_remediable

          MANUAL_REMEDIATION_GUIDE = {
            'prowler-s3_bucket_no_mfa_delete': {
              'reason': 'S3 MFA Delete 활성화는 루트 계정 자격증명+MFA 토큰이 동시에 필요하며, Terraform/SDK에서 루트 세션을 지원하지 않아 자동화 불가',
              'guide': '1. 루트 계정으로 AWS CLI 로그인 → 2. aws s3api put-bucket-versioning --bucket {버킷명} --versioning-configuration Status=Enabled,MFADelete=Enabled --mfa "arn:aws:iam::{계정ID}:mfa/root-account-mfa {TOTP코드}"',
            },
            'prowler-iam_root_hardware_mfa_enabled': {
              'reason': '하드웨어 MFA 디바이스 등록은 물리적 디바이스가 필요하며, AWS 콘솔에서만 직접 조작 가능',
              'guide': '1. AWS 콘솔 → IAM → 보안 자격증명 → 2. MFA 디바이스 → 하드웨어 MFA 디바이스 활성화 → 3. 호환 장치: YubiKey(FIDO2), Gemalto 토큰',
            },
            'prowler-ec2_ebs_volume_encryption': {
              'reason': '기존 EBS 볼륨 암호화 전환은 인스턴스 중단 및 볼륨 교체가 필요하여 서비스 영향 발생',
              'guide': '1. 인스턴스 중지 → 2. 볼륨 스냅샷 생성 → 3. 스냅샷 암호화 복사(KMS 키 지정) → 4. 암호화 스냅샷으로 새 볼륨 생성 → 5. 기존 볼륨 분리 후 새 볼륨 연결 → 6. 인스턴스 시작 및 검증',
            },
            'prowler-ec2_instance_profile_attached': {
              'reason': 'EC2 인스턴스 프로파일 연결은 실행 중인 애플리케이션 권한에 영향을 주어 사전 검토 및 수동 적용 필요',
              'guide': '1. 적절한 권한의 IAM 역할 생성 → 2. EC2 콘솔 → 인스턴스 → 작업 → 보안 → IAM 역할 수정 → 3. 생성한 IAM 역할 연결 및 저장',
            },
          }

          def make_comparison_section(title, asis_counts, is_counts, before_lbl, after_lbl):
            def tbl(counts):
              rows = ''.join(f'<tr><td><code>{cid}</code></td><td align="right">{counts[cid]}</td></tr>' for cid in sorted(counts))
              if not rows: rows = '<tr><td>없음</td><td align="right">0</td></tr>'
              return f'<table><tr><th>점검 항목 ID</th><th>FAIL</th></tr>{rows}</table>'
            return (
              f'### {title}\n\n'
              f'<table><tr valign="top">'
              f'<td><b>{before_lbl}</b><br>{tbl(asis_counts)}</td>'
              f'<td align="center" valign="middle">&nbsp;→&nbsp;</td>'
              f'<td><b>{after_lbl}</b><br>{tbl(is_counts)}</td>'
              f'</tr></table>'
            )

          def make_service_comparison(asis_rows, is_rows, before_lbl, after_lbl):
            def svc_counts(rows):
              c = {}
              for r in rows:
                svc = str(r.get('service', 'unknown')).lower().strip() or 'unknown'
                c[svc] = c.get(svc, 0) + 1
              return c
            asis_c = svc_counts(asis_rows)
            is_c = svc_counts(is_rows)
            all_svcs = sorted(set(list(asis_c.keys()) + list(is_c.keys())))
            def tbl(counts):
              rows = ''.join(f'<tr><td><code>{svc}</code></td><td align="right">{counts[svc]}</td></tr>' for svc in all_svcs if svc in counts)
              if not rows: rows = '<tr><td>없음</td><td align="right">0</td></tr>'
              return f'<table><tr><th>서비스</th><th>FAIL 수</th></tr>{rows}</table>'
            return (
              '### 서비스별 FAIL 변화\n\n'
              f'<table><tr valign="top">'
              f'<td><b>{before_lbl}</b><br>{tbl(asis_c)}</td>'
              f'<td align="center" valign="middle">&nbsp;→&nbsp;</td>'
              f'<td><b>{after_lbl}</b><br>{tbl(is_c)}</td>'
              f'</tr></table>'
            )

          before_lbl = 'AS-IS (개선 전)'
          after_lbl = 'TO-BE (개선 후)'
          if prev_post_path.exists():
            prev_fail_all = [x for x in json.loads(prev_post_path.read_text(encoding='utf-8')) if x.get('status') == 'FAIL']
          else:
            bl_path = Path('artifacts/baseline_scan/prioritized_findings.json')
            prev_fail_all = [x for x in json.loads(bl_path.read_text(encoding='utf-8')) if x.get('status') == 'FAIL'] if bl_path.exists() else []

          asis_total_counts = {}
          asis_remediable_counts = {}
          for row in prev_fail_all:
            cid = str(row.get('check_id', 'unknown'))
            asis_total_counts[cid] = asis_total_counts.get(cid, 0) + 1
            if not is_manual_runbook(row):
              asis_remediable_counts[cid] = asis_remediable_counts.get(cid, 0) + 1

          rem_table_lines = [
            '| 남은 점검 항목 | 건수 |',
            '|---|---:|',
          ]
          if s['remaining_fail_check_ids']:
            for cid in sorted(s['remaining_fail_check_ids']):
              rem_table_lines.append(f'| `{cid}` | {int(total_fail_counts.get(cid, 0))} |')
          else:
            rem_table_lines.append('| 없음 | 0 |')

          remediable_table_lines = [
            '| 점검 항목 (Terraform 가능) | 건수 |',
            '|---|---:|',
          ]
          if remediable_fail_counts:
            for cid in sorted(remediable_fail_counts):
              remediable_table_lines.append(f'| `{cid}` | {int(remediable_fail_counts.get(cid, 0))} |')
          else:
            remediable_table_lines.append('| 없음 | 0 |')

          manual_table_lines = [
            '| 점검 항목 (수동 조치 필요) | 건수 |',
            '|---|---:|',
          ]
          if manual_fail_counts:
            for cid in sorted(manual_fail_counts):
              manual_table_lines.append(f'| `{cid}` | {int(manual_fail_counts.get(cid, 0))} |')
          else:
            manual_table_lines.append('| 없음 | 0 |')
          manual_table = '\n'.join(manual_table_lines)

          manual_guide_lines = []
          if manual_fail_counts:
            manual_guide_lines.append('\n**조치 가이드:**')
            for cid in sorted(manual_fail_counts):
              guide_info = MANUAL_REMEDIATION_GUIDE.get(cid)
              if guide_info:
                manual_guide_lines.append(f'\n**`{cid}`**')
                manual_guide_lines.append(f'- **수동 처리 이유:** {guide_info["reason"]}')
                manual_guide_lines.append(f'- **조치 방법:** {guide_info["guide"]}')
              else:
                manual_guide_lines.append(f'\n**`{cid}`**')
                manual_guide_lines.append('- 콘솔에서 직접 처리해야 하는 항목입니다.')

          now_lines = [
            '### 지속 자동화 가능 항목',
          ]
          if remediable_fail_counts:
            now_lines.append(f'- Terraform으로 더 줄일 수 있는 FAIL: {current_remediable_fail}')
            now_lines.append('- PR 생성 → 병합 → 적용 → 재스캔 순서로 계속 진행')
          else:
            now_lines.append('- Terraform으로 처리할 수 있는 FAIL은 남아 있지 않습니다.')
            now_lines.append('- 남은 건 아래 수동 조치 목록 위주로 처리하면 됩니다.')

          later_lines = [
            '### 수동 처리 현황',
            f'- 수동 조치 필요 FAIL: {current_manual_fail}',
            '- AWS 콘솔 직접 작업 또는 계정/조직 단위 정책 변경이 필요한 항목입니다.',
          ]

          md = (
            '## 04. 재스캔 결과 요약\n\n'
            f'- 기준 FAIL: {s["baseline_fail"]}\n'
            f'- 현재 FAIL: {s["post_fail"]}\n'
            f'- 줄어든 FAIL: {s["reduced"]} (기준 대비)\n'
            f'- Terraform 처리 가능 FAIL: {current_remediable_fail}\n'
            f'- 수동 처리 필요 FAIL: {current_manual_fail}\n\n'
            + make_service_comparison(prev_fail_all, current_fail_rows, before_lbl, after_lbl) + '\n\n'
            + make_comparison_section('전체 FAIL 변화', asis_total_counts, total_fail_counts, before_lbl, after_lbl) + '\n\n'
            + make_comparison_section('Terraform 자동화 가능 FAIL 변화', asis_remediable_counts, remediable_fail_counts, before_lbl, after_lbl) + '\n\n'
            + '### 수동 조치 항목\n'
            + manual_table + '\n'
            + ('\n'.join(manual_guide_lines) if manual_guide_lines else '')
            + '\n\n'
            + '\n'.join(now_lines)
            + '\n\n'
            + '\n'.join(later_lines)
            + '\n'
          )
          summary_path.write_text(json.dumps(s, indent=2), encoding='utf-8')
          Path('artifacts/rescan/rescan_summary.md').write_text(md, encoding='utf-8')
          print(md)
          PY
          cat artifacts/rescan/rescan_summary.md >> "$GITHUB_STEP_SUMMARY"
          python - <<'PY'
          import json
          from pathlib import Path
          s = json.loads(Path('artifacts/rescan/rescan_summary.json').read_text(encoding='utf-8'))
          incremental = s.get("incremental_reduced_remediable")
          if incremental is None:
              incremental = s.get("incremental_reduced")
          new_remediable = s.get("new_fail_since_previous_remediable_check_ids", []) or []
          if incremental is not None:
              if incremental < 0:
                  if new_remediable:
                      raise SystemExit(
                          "FAIL increased with new terraform-capable checks since previous rescan: "
                          f"new={','.join(new_remediable)} "
                          f"previous_post_remediable={s.get('previous_post_fail_remediable', s.get('previous_post_fail'))} "
                          f"current_post_remediable={s.get('post_fail_remediable', s.get('post_fail'))}"
                      )
                  Path("artifacts/rescan/no_reduction.flag").write_text("1", encoding="utf-8")
                  print(
                      "WARNING: remediable fail count increased but no new check IDs "
                      "(count fluctuation/noise treated as neutral): "
                      f"previous_post_remediable={s.get('previous_post_fail_remediable', s.get('previous_post_fail'))} "
                      f"current_post_remediable={s.get('post_fail_remediable', s.get('post_fail'))}"
                  )
              if incremental == 0:
                  Path("artifacts/rescan/no_reduction.flag").write_text("1", encoding="utf-8")
                  print(
                      "WARNING: no additional reduction vs previous post (terraform-capable scope): "
                      f"previous_post_remediable={s.get('previous_post_fail_remediable', s.get('previous_post_fail'))} "
                      f"current_post_remediable={s.get('post_fail_remediable', s.get('post_fail'))}"
                  )
          elif s.get("reduced", 0) <= 0:
              raise SystemExit(f"FAIL not reduced vs baseline: baseline={s.get('baseline_fail')} post={s.get('post_fail')}")
          PY

      - name: Comment on merged PR when no additional reduction
        if: always()
        shell: bash
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          if [ ! -f artifacts/rescan/no_reduction.flag ]; then
            echo "no neutral warning; skip PR comment"
            exit 0
          fi
          TITLE='${{ github.event.workflow_run.display_title }}'
          if [[ "$TITLE" =~ \#([0-9]+) ]]; then
            PR_NUMBER="${BASH_REMATCH[1]}"
          else
            echo "could not parse PR number from title: $TITLE"
            exit 0
          fi
          MSG=$'이번 병합으로 FAIL이 추가로 줄지 않았습니다.\n\n- 결과: 변화 없음 (적용은 성공했으나 FAIL 수 유지)\n- 남은 항목은 워크플로우 요약 또는 아티팩트 `rescan-${{ github.run_id }}`에서 확인하세요.'
          gh pr comment "$PR_NUMBER" --repo "${{ github.repository }}" --body "$MSG" || true

      - name: Optional publish rescan result to external API
        continue-on-error: true
        env:
          PROWLER_APP_API_URL: ${{ secrets.PROWLER_APP_API_URL }}
          PROWLER_APP_API_TOKEN: ${{ secrets.PROWLER_APP_API_TOKEN }}
        run: |
          if [ -z "$PROWLER_APP_API_URL" ] || [ -z "$PROWLER_APP_API_TOKEN" ]; then
            echo "skip publish: PROWLER_APP_API_URL or PROWLER_APP_API_TOKEN is empty"
            exit 0
          fi
          CALLER_ACCOUNT_ID="$(aws sts get-caller-identity --query Account --output text 2>/dev/null || echo "")"
          python iac/scripts/publish_scan_to_api.py \
            --input artifacts/rescan/rescan_summary.json \
            --event rescan_verify \
            --api-url "$PROWLER_APP_API_URL" \
            --api-token "$PROWLER_APP_API_TOKEN" \
            --repo "${{ github.repository }}" \
            --run-id "${{ github.run_id }}" \
            --account-id "$CALLER_ACCOUNT_ID" \
            --region "ap-northeast-2" \
            --framework "cis_1.4_plus_isms_p"

      - name: Upload rescan artifacts
        uses: actions/upload-artifact@v4
        with:
          name: rescan-${{ github.run_id }}
          path: artifacts/rescan/
