name: Security Pipeline - 01 Scan Baseline

on:
  workflow_dispatch:
    inputs:
      deploy_vulnerable:
        description: "Deploy vulnerable infra before scan"
        required: true
        type: boolean
        default: true
      account_id:
        description: "Target AWS account id"
        required: true
        type: string
      region:
        description: "Target AWS region"
        required: true
        type: string
        default: us-east-1
      scan_id:
        description: "Prowler App scan UUID (optional, used to activate download button)"
        required: false
        type: string
        default: ""

concurrency:
  group: security-pipeline-01-scan-${{ github.ref }}
  cancel-in-progress: true

permissions:
  id-token: write
  contents: read

jobs:
  scan:
    runs-on: ubuntu-latest
    env:
      AWS_REGION: ${{ inputs.region }}
      AWS_ACCOUNT_ID: ${{ inputs.account_id }}
      TF_VAR_region: ${{ inputs.region }}
      TF_VAR_account_id: ${{ inputs.account_id }}
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: ${{ inputs.region }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      # -------------------------------------------------------
      # 이전 실행 누적 리소스 정리 (로컬 state 없이 재실행 시 중복 생성 방지)
      # ProwlerDemo=vulnerable_infra_test 태그가 붙은 SG·S3·LogGroup 삭제
      # -------------------------------------------------------
      - name: Cleanup leftover vulnerable infra (pre-deploy)
        if: inputs.deploy_vulnerable == true
        continue-on-error: true
        env:
          AWS_REGION: ${{ inputs.region }}
        run: |
          TAG_KEY="ProwlerDemo"
          TAG_VAL="vulnerable_infra_test"
          REGION="${{ inputs.region }}"

          echo "=== [Cleanup] Security Groups ==="
          SG_IDS=$(aws ec2 describe-security-groups \
            --region "$REGION" \
            --filters "Name=tag:${TAG_KEY},Values=${TAG_VAL}" \
            --query "SecurityGroups[*].GroupId" \
            --output text 2>/dev/null || true)
          for SG in $SG_IDS; do
            echo "  삭제: $SG"
            aws ec2 delete-security-group --region "$REGION" --group-id "$SG" 2>/dev/null || true
          done
          echo "  완료 ($(echo $SG_IDS | wc -w)개)"

          echo "=== [Cleanup] S3 Buckets (vuln-demo-*) ==="
          BUCKETS=$(aws s3api list-buckets \
            --query "Buckets[?starts_with(Name,'vuln-demo-')].Name" \
            --output text 2>/dev/null || true)
          for BUCKET in $BUCKETS; do
            echo "  삭제: $BUCKET"
            aws s3 rb "s3://${BUCKET}" --force 2>/dev/null || true
          done
          echo "  완료 ($(echo $BUCKETS | wc -w)개)"

          echo "=== [Cleanup] CloudWatch Log Groups (/vuln/*) ==="
          LOG_GROUPS=$(aws logs describe-log-groups \
            --region "$REGION" \
            --log-group-name-prefix "/vuln/" \
            --query "logGroups[*].logGroupName" \
            --output text 2>/dev/null || true)
          for LG in $LOG_GROUPS; do
            echo "  삭제: $LG"
            aws logs delete-log-group --region "$REGION" --log-group-name "$LG" 2>/dev/null || true
          done
          echo "  완료 ($(echo $LOG_GROUPS | wc -w)개)"

      - name: Deploy vulnerable infra
        if: inputs.deploy_vulnerable == true
        run: |
          terraform -chdir=terraform/vulnerable_infra_test init -input=false
          terraform -chdir=terraform/vulnerable_infra_test apply -auto-approve -input=false

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install tooling
        run: |
          python -m pip install --upgrade pip
          pip install "prowler>=3.11,<4.0"

      - name: Run Prowler CIS 1.4
        run: |
          mkdir -p artifacts/scan
          prowler aws --compliance cis_1.4_aws -M json-asff -o artifacts/scan -F baseline || true
          FOUND="$(find artifacts/scan -maxdepth 1 -type f -name 'baseline*.json*' | head -n 1)"
          if [ -z "$FOUND" ]; then
            echo "[]" > artifacts/scan/baseline.asff.json
          else
            TARGET="$(realpath artifacts/scan/baseline.asff.json)"
            SRC="$(realpath "$FOUND")"
            if [ "$SRC" != "$TARGET" ]; then
              cp "$FOUND" artifacts/scan/baseline.asff.json
            fi
          fi

      - name: Normalize and score findings
        run: |
          python iac/scripts/normalize_findings.py \
            --input artifacts/scan/baseline.asff.json \
            --output artifacts/scan/normalized_findings.json \
            --account-id "${{ inputs.account_id }}" \
            --region "${{ inputs.region }}"
          python iac/scripts/osfp_score.py \
            --input artifacts/scan/normalized_findings.json \
            --output artifacts/scan/prioritized_findings.json

      - name: Build scan manifest
        run: |
          python iac/scripts/write_scan_manifest.py \
            --normalized artifacts/scan/normalized_findings.json \
            --prioritized artifacts/scan/prioritized_findings.json \
            --output artifacts/scan/scan_manifest.json \
            --account-id "${{ inputs.account_id }}" \
            --region "${{ inputs.region }}"

      - name: Upload scan artifact
        uses: actions/upload-artifact@v4
        with:
          name: scan-${{ github.run_id }}
          path: artifacts/scan/

      - name: Upload report to Prowler App
        if: inputs.scan_id != ''
        continue-on-error: true
        env:
          PROWLER_APP_API_URL: ${{ secrets.PROWLER_APP_API_URL }}
          PROWLER_APP_API_TOKEN: ${{ secrets.PROWLER_APP_API_TOKEN }}
        run: |
          SCAN_ID="${{ inputs.scan_id }}"
          if [ -z "$SCAN_ID" ] || [ -z "$PROWLER_APP_API_URL" ]; then
            echo "skip report upload: scan_id or PROWLER_APP_API_URL not set"
            exit 0
          fi
          cd artifacts/scan
          zip -r scan-report.zip . -x "*.zip"
          cd -
          curl -sf -X POST \
            -H "Authorization: Bearer $PROWLER_APP_API_TOKEN" \
            -F "scan_id=${SCAN_ID}" \
            -F "report_zip=@artifacts/scan/scan-report.zip" \
            "${PROWLER_APP_API_URL%/}/api/v1/pipeline-publish/scan-output" \
            && echo "report uploaded: scan_id=${SCAN_ID}" \
            || echo "report upload failed (non-fatal)"

      - name: Summary
        run: |
          python - <<'PY'
          import json
          from collections import defaultdict
          from pathlib import Path

          p = Path('artifacts/scan/prioritized_findings.json')
          rows = json.loads(p.read_text(encoding='utf-8')) if p.exists() else []

          SEV_COLS = ['critical', 'high', 'medium', 'low', 'info']

          def get_sev(row):
              sev = row.get('severity') or row.get('Severity') or ''
              if isinstance(sev, dict):
                  sev = sev.get('Label', '')
              sev = str(sev).lower().strip()
              return sev.replace('informational', 'info') if sev in (*SEV_COLS, 'informational') else 'info'

          svcs = defaultdict(lambda: {'fail': 0, 'pass': 0, **{s: 0 for s in SEV_COLS}})
          for r in rows:
              svc = str(r.get('service', 'unknown')).lower().strip() or 'unknown'
              if str(r.get('status', '')).upper() == 'FAIL':
                  svcs[svc]['fail'] += 1
                  svcs[svc][get_sev(r)] += 1
              else:
                  svcs[svc]['pass'] += 1

          fail_total = sum(v['fail'] for v in svcs.values())
          print(f"baseline_fail={fail_total}")

          lines = [
              '## 01. 기준 스캔 결과',
              '',
              f'- 기준 FAIL 항목 수: **{fail_total}**',
              '',
              '| Provider | 서비스 | 상태 | Critical | High | Medium | Low | Info |',
              '|---|---|---|---:|---:|---:|---:|---:|',
          ]
          for svc in sorted(svcs.keys()):
              d = svcs[svc]
              fail_n, pass_n = d['fail'], d['pass']
              if fail_n > 0:
                  status_str = f'fail ({fail_n})'
                  sevs = [str(d[s]) if d[s] else '0' for s in SEV_COLS]
              else:
                  status_str = f'pass ({pass_n})'
                  sevs = ['-'] * len(SEV_COLS)
              lines.append(f'| aws | `{svc}` | {status_str} | {" | ".join(sevs)} |')

          with open(Path.cwd() / 'summary.md', 'w', encoding='utf-8') as f:
              f.write('\n'.join(lines) + '\n')
          PY
          cat summary.md >> "$GITHUB_STEP_SUMMARY"
 